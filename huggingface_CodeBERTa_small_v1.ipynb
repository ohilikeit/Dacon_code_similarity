{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ohilikeit/Dacon_code_similarity/blob/main/huggingface_CodeBERTa_small_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1olcCpkHEjA",
        "outputId": "a6fdb992-8f02-4eef-e5db-04c3becfcf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gkXaT59FHHmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac9da4e-e26a-4879-afe6-716c1b19417b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/code_similarity\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/code_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "ZZ8YobNTL8X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('train_data.csv')\n",
        "sample_train = pd.read_csv('sample_train.csv')\n",
        "sum_data = pd.concat([df, sample_train], axis = 0)\n",
        "sum_data = sum_data(frac=1).reset_index(drop=True, inplace=True)\n",
        "sum_data.to_csv('train_2.csv')\n",
        "del df, sample_train, sum_data"
      ],
      "metadata": {
        "id": "lh6EPYMzrSQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8-_bQ9WqEHc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback, RobertaForMaskedLM, RobertaTokenizer, RobertaForSequenceClassification\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers.utils import logging\n",
        "\n",
        "MODEL = \"huggingface/CodeBERTa-small-v1\"\n",
        "INPUT = \"train_2.csv\"\n",
        "MAX_LEN = 512\n",
        "dataset = load_dataset(\"csv\", data_files=INPUT)['train']\n",
        "tokenizer = RobertaTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "#logging.set_verbosity_error() \n",
        "logging.set_verbosity_info() \n",
        "#--> 두번째에 이거로 교체 후 다시 돌리기 \n",
        "def example_fn(examples):\n",
        "    outputs = tokenizer(examples['code1'], examples['code2'], padding=True, max_length=MAX_LEN,truncation=True)\n",
        "    if 'similar' in examples:\n",
        "        outputs[\"labels\"] = examples[\"similar\"]\n",
        "    return outputs\n",
        "\n",
        "dataset = dataset.map(example_fn, remove_columns=['code1', 'code2', 'similar'])\n",
        "dataset = dataset.train_test_split(0.1)\n",
        "\n",
        "_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "_metric = load_metric(\"glue\", \"sst2\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds, labels = p\n",
        "    output =  _metric.compute(references=labels, predictions=np.argmax(preds, axis=-1),)\n",
        "    return output\n",
        "    \n",
        "model = RobertaForSequenceClassification.from_pretrained(MODEL) \n",
        "\n",
        "args = TrainingArguments(\n",
        "    'experience',\n",
        "    evaluation_strategy = 'steps',\n",
        "    eval_steps = 500,\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model='accuracy', # validation loss\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay= 0.01,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    save_strategy='steps',\n",
        "    logging_strategy=\"steps\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        data_collator=_collator,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "IpbGs0kEMjc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89241fee-14d2-46b9-c25e-d5cde4994609"
      },
      "execution_count": 65,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 478212\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 44835\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3001' max='44835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3001/44835 2:26:44 < 34:06:59, 0.34 it/s, Epoch 0.20/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.383300</td>\n",
              "      <td>0.208661</td>\n",
              "      <td>0.922424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.211700</td>\n",
              "      <td>0.160299</td>\n",
              "      <td>0.940679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>0.134393</td>\n",
              "      <td>0.949562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.164200</td>\n",
              "      <td>0.155123</td>\n",
              "      <td>0.940924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.120670</td>\n",
              "      <td>0.954286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1303' max='1661' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1303/1661 11:26 < 03:08, 1.90 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-500\n",
            "Configuration saved in experience/checkpoint-500/config.json\n",
            "Model weights saved in experience/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-1000\n",
            "Configuration saved in experience/checkpoint-1000/config.json\n",
            "Model weights saved in experience/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-1500\n",
            "Configuration saved in experience/checkpoint-1500/config.json\n",
            "Model weights saved in experience/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-1500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-2000\n",
            "Configuration saved in experience/checkpoint-2000/config.json\n",
            "Model weights saved in experience/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-2000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-2500\n",
            "Configuration saved in experience/checkpoint-2500/config.json\n",
            "Model weights saved in experience/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-2500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15000' max='44835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15000/44835 13:26:42 < 26:44:46, 0.31 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.383300</td>\n",
              "      <td>0.208661</td>\n",
              "      <td>0.922424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.211700</td>\n",
              "      <td>0.160299</td>\n",
              "      <td>0.940679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>0.134393</td>\n",
              "      <td>0.949562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.164200</td>\n",
              "      <td>0.155123</td>\n",
              "      <td>0.940924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.120670</td>\n",
              "      <td>0.954286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.138400</td>\n",
              "      <td>0.113506</td>\n",
              "      <td>0.958182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.124700</td>\n",
              "      <td>0.102113</td>\n",
              "      <td>0.963602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.108505</td>\n",
              "      <td>0.963847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.095720</td>\n",
              "      <td>0.965296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.117200</td>\n",
              "      <td>0.119209</td>\n",
              "      <td>0.958220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.108300</td>\n",
              "      <td>0.108785</td>\n",
              "      <td>0.964995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.119800</td>\n",
              "      <td>0.086969</td>\n",
              "      <td>0.970170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.108400</td>\n",
              "      <td>0.106284</td>\n",
              "      <td>0.967404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.102200</td>\n",
              "      <td>0.081084</td>\n",
              "      <td>0.971770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.099200</td>\n",
              "      <td>0.120416</td>\n",
              "      <td>0.963677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.093300</td>\n",
              "      <td>0.086075</td>\n",
              "      <td>0.972673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.079647</td>\n",
              "      <td>0.972146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.090900</td>\n",
              "      <td>0.078066</td>\n",
              "      <td>0.973294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.097600</td>\n",
              "      <td>0.075012</td>\n",
              "      <td>0.975572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.085100</td>\n",
              "      <td>0.075561</td>\n",
              "      <td>0.975496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.082255</td>\n",
              "      <td>0.972109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.087100</td>\n",
              "      <td>0.075791</td>\n",
              "      <td>0.976287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.080900</td>\n",
              "      <td>0.076721</td>\n",
              "      <td>0.976682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.086700</td>\n",
              "      <td>0.069807</td>\n",
              "      <td>0.979373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.081600</td>\n",
              "      <td>0.070355</td>\n",
              "      <td>0.977341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.078100</td>\n",
              "      <td>0.071009</td>\n",
              "      <td>0.976946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.076600</td>\n",
              "      <td>0.059154</td>\n",
              "      <td>0.980126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.076400</td>\n",
              "      <td>0.071869</td>\n",
              "      <td>0.978206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.074200</td>\n",
              "      <td>0.068887</td>\n",
              "      <td>0.978733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.073900</td>\n",
              "      <td>0.078461</td>\n",
              "      <td>0.977604</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to experience/checkpoint-3000\n",
            "Configuration saved in experience/checkpoint-3000/config.json\n",
            "Model weights saved in experience/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-3000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-3500\n",
            "Configuration saved in experience/checkpoint-3500/config.json\n",
            "Model weights saved in experience/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-3500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-4000\n",
            "Configuration saved in experience/checkpoint-4000/config.json\n",
            "Model weights saved in experience/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-4000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-4500\n",
            "Configuration saved in experience/checkpoint-4500/config.json\n",
            "Model weights saved in experience/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-4500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-5000\n",
            "Configuration saved in experience/checkpoint-5000/config.json\n",
            "Model weights saved in experience/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-5000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-5500\n",
            "Configuration saved in experience/checkpoint-5500/config.json\n",
            "Model weights saved in experience/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-5500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-6000\n",
            "Configuration saved in experience/checkpoint-6000/config.json\n",
            "Model weights saved in experience/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-6000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-6500\n",
            "Configuration saved in experience/checkpoint-6500/config.json\n",
            "Model weights saved in experience/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-6500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-7000\n",
            "Configuration saved in experience/checkpoint-7000/config.json\n",
            "Model weights saved in experience/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-7000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-7500\n",
            "Configuration saved in experience/checkpoint-7500/config.json\n",
            "Model weights saved in experience/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-7500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-8000\n",
            "Configuration saved in experience/checkpoint-8000/config.json\n",
            "Model weights saved in experience/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-8000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-8500\n",
            "Configuration saved in experience/checkpoint-8500/config.json\n",
            "Model weights saved in experience/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-8500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-9000\n",
            "Configuration saved in experience/checkpoint-9000/config.json\n",
            "Model weights saved in experience/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-9000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-9500\n",
            "Configuration saved in experience/checkpoint-9500/config.json\n",
            "Model weights saved in experience/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-9500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-10000\n",
            "Configuration saved in experience/checkpoint-10000/config.json\n",
            "Model weights saved in experience/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-10000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-10500\n",
            "Configuration saved in experience/checkpoint-10500/config.json\n",
            "Model weights saved in experience/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-10500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-11000\n",
            "Configuration saved in experience/checkpoint-11000/config.json\n",
            "Model weights saved in experience/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-11000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-11500\n",
            "Configuration saved in experience/checkpoint-11500/config.json\n",
            "Model weights saved in experience/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-11500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-12000\n",
            "Configuration saved in experience/checkpoint-12000/config.json\n",
            "Model weights saved in experience/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-12000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-12500\n",
            "Configuration saved in experience/checkpoint-12500/config.json\n",
            "Model weights saved in experience/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-12500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-13000\n",
            "Configuration saved in experience/checkpoint-13000/config.json\n",
            "Model weights saved in experience/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-13000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-13500\n",
            "Configuration saved in experience/checkpoint-13500/config.json\n",
            "Model weights saved in experience/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-13500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-14000\n",
            "Configuration saved in experience/checkpoint-14000/config.json\n",
            "Model weights saved in experience/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-14000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-14500\n",
            "Configuration saved in experience/checkpoint-14500/config.json\n",
            "Model weights saved in experience/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-14500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Unnamed: 0. If Unnamed: 0 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 53135\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to experience/checkpoint-15000\n",
            "Configuration saved in experience/checkpoint-15000/config.json\n",
            "Model weights saved in experience/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in experience/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in experience/checkpoint-15000/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from experience/checkpoint-13500 (score: 0.9801260939117342).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=15000, training_loss=0.11709304682413738, metrics={'train_runtime': 48404.3445, 'train_samples_per_second': 29.639, 'train_steps_per_second': 0.926, 'total_flos': 6.353305335475046e+16, 'train_loss': 0.11709304682413738, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IVC9yB8qDVa",
        "outputId": "4930f004-8b7c-46dc-fae5-8ae60423206c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "logging.set_verbosity_error() \n",
        "TEST = \"test.csv\"\n",
        "SUB = \"sample_submission.csv\"\n",
        "\n",
        "test_dataset = load_dataset(\"csv\", data_files=TEST)['train']\n",
        "test_dataset = test_dataset.map(example_fn, remove_columns=['code1', 'code2'])\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "df = pd.read_csv(SUB)\n",
        "df['similar'] = np.argmax(predictions.predictions, axis=-1)\n",
        "df.to_csv('experience_submit.csv', index=False)\n",
        "df"
      ],
      "metadata": {
        "id": "hnfqUQyBF6F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a73bf3-e7b7-4571-d6fc-e330639b312e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         1\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "179695    1\n",
              "179696    1\n",
              "179697    0\n",
              "179698    1\n",
              "179699    1\n",
              "Name: similar, Length: 179700, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "huggingface/CodeBERTa-small-v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}